{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a review index from 0 to 6700 :\n",
      "223\n",
      "Is this the review you want to classify? (y/n)\n",
      "\n",
      "I can't remember which dogs I had (friends picked up the food) but they were really delicious!! Not too impressed with their duck fat fries as it tasted pretty much just like regular fries to me with no trace of duck.\n",
      "y\n",
      "Generating output...\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "\n",
    "# pickle will be used to load the saved classifier and \n",
    "# test data to be used for the front end\n",
    "import pickle\n",
    "# scikit-learn will be used for getting the decision path\n",
    "# of samples and generating the tree diagram\n",
    "from sklearn import tree\n",
    "# pydotplus will be used to create an interface to the \n",
    "# DOT language which will be used to modify the tree diagram\n",
    "import pydotplus\n",
    "# webbrowser will be used to open a new tab with the \n",
    "# content of the HTML file created\n",
    "import webbrowser\n",
    "# import datetime - for including the current date \n",
    "# and time in the HTML file generated\n",
    "import datetime\n",
    "# import functionality to get the current directory path\n",
    "from pathlib import Path\n",
    "\n",
    "####################################################\n",
    "####################################################\n",
    "\n",
    "\n",
    "# Define functions to be used for generating the front end\n",
    "\n",
    "# function 1 - generates for a sample review the decision path information\n",
    "# inspiration from: \n",
    "# https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html#decision-path\n",
    "def get_decision_path_info(classifier, feature_names, sample):\n",
    "\n",
    "    # retrieve probabilities for classification for sample\n",
    "    probabilities = classifier.predict_proba(sample)\n",
    "    # retrieve decision paths for test sample\n",
    "    node_indicator = classifier.decision_path(sample)\n",
    "    # retrieve leaf IDs reached by test sample\n",
    "    leaf_identifier = classifier.apply(sample)\n",
    "    # get a list of all thresholds (of all nodes in tree)\n",
    "    threshold = classifier.tree_.threshold\n",
    "    # get node id of leaf that the sample \"lands on\"\n",
    "    leaf_id = leaf_identifier[0]\n",
    "    # obtain ids of the nodes sample goes through\n",
    "    nodes_traversed = node_indicator.indices[node_indicator.indptr[0]:\n",
    "                                    node_indicator.indptr[1]]\n",
    "\n",
    "    features_used = []\n",
    "    threshold_values = [] \n",
    "    threshold_signs = []\n",
    "\n",
    "    for node_id in nodes_traversed:\n",
    "        \n",
    "        # break for loop\n",
    "        if(node_id == leaf_id):\n",
    "            break\n",
    "\n",
    "        # check if value of the split feature for sample i is below threshold\n",
    "        if (sample.iloc[0][classifier.tree_.feature[node_id]] <= threshold[node_id]):\n",
    "            threshold_sign = \"<=\"\n",
    "        else:\n",
    "            threshold_sign = \">\"\n",
    "            \n",
    "        features_used.append(feature_names[classifier.tree_.feature[node_id]])\n",
    "        #thresholds.append(threshold_sign + \" \" + str(round(threshold[node_id], 3)))\n",
    "        threshold_values.append(round(threshold[node_id], 3))\n",
    "        threshold_signs.append(threshold_sign)\n",
    "\n",
    "    # get proportions of labels at leaf node and calculate probabilities of the output\n",
    "    class_proportion = classifier.tree_.value[leaf_id]\n",
    "    class_probability = round(100 * max(probabilities[0]), 1)\n",
    "    samples_at_leaf = int(class_proportion[0][0]) + int(class_proportion[0][1])\n",
    "    genuine_probability = round(100 * probabilities[0][0], 1)\n",
    "    fake_probability = round(100 * probabilities[0][1], 1)\n",
    "\n",
    "    predicted_string = \"According to the model, this review is likely to be Genuine with \" \\\n",
    "    \"probability {prob1}% and Fake with probability {prob2}%. \" \\\n",
    "    .format(prob1 = genuine_probability, prob2 = fake_probability)\n",
    "    predicted_string += \"These probabilities are based on \" + str(samples_at_leaf) + \\\n",
    "    \" other reviews with the same decision path.\"\n",
    "    \n",
    "    return features_used, threshold_values, threshold_signs, predicted_string\n",
    "\n",
    "# function 2 - this function writes the series of decisions in a natural language form\n",
    "# based on the features used and their associated thresholds\n",
    "# in the decision path\n",
    "# returns the series of decisions and the \n",
    "# features not used in the decision path\n",
    "def write_decisions(features_used, feature_names, threshold_values, threshold_signs):\n",
    "    \n",
    "    unique_features = []\n",
    "    features_not_used = []\n",
    "    list_of_statements = []\n",
    "    \n",
    "    # create list of unique features (in the order they appear in decision path) \n",
    "    # (not efficient but our lists will be very small)\n",
    "    for feature in features_used:\n",
    "        if(feature not in unique_features):\n",
    "            unique_features.append(feature)\n",
    "            \n",
    "    # create list of features not used in decision path\n",
    "    # (not efficient but our lists will be very small)\n",
    "    for feature in feature_names:\n",
    "        if(feature not in unique_features):\n",
    "            features_not_used.append(feature)\n",
    "\n",
    "    # create a dict with all unique features and the number of times\n",
    "    # they appear in the decision path\n",
    "    feature_counts = dict((element,0) for element in unique_features)\n",
    "\n",
    "    # loop through each decision\n",
    "    for index in range(len(features_used)):\n",
    "        \n",
    "        # update feature count in dict\n",
    "        feature_counts[features_used[index]] += 1\n",
    "        \n",
    "        # handle case when feature is 'hasProfile'\n",
    "        if(features_used[index] == \"Does the reviewer have a profile?\"):\n",
    "            if(threshold_signs[index] == \">\"):\n",
    "                list_of_statements.append(\"The reviewer has a profile\")\n",
    "            elif(threshold_signs[index] == \"<=\"):\n",
    "                list_of_statements.append(\"The reviewer does not have a profile\")\n",
    "            continue\n",
    "        # handle the cases where the threshold should \n",
    "        # be rounded to an integer\n",
    "        # i.e., when the feature is not max_tfidf or 'hasProfile'\n",
    "        elif(features_used[index] != \"Maximum word importance score (TF-IDF)\"):\n",
    "            \n",
    "            # if threshold sign is '>', add 0.5 to the value and change sign to '>='\n",
    "            if(threshold_signs[index] == \">\"):\n",
    "                threshold_values[index] += 0.5\n",
    "                threshold_signs[index] = \">=\"\n",
    "            # if threshold sign is '<=', subtract 0.5 from the value and keep the same sign\n",
    "            elif(threshold_signs[index] == \"<=\"):\n",
    "                threshold_values[index] -= 0.5\n",
    "                \n",
    "            # if threshold sign is '<=' and value is 0, update sign to be '='\n",
    "            if(threshold_signs[index] == \"<=\" and threshold_values[index] == 0):\n",
    "                threshold_signs[index] = \"=\"\n",
    "\n",
    "        # create statements based on feature counts\n",
    "        if(feature_counts[features_used[index]] == 1):\n",
    "            list_of_statements.append(features_used[index] \\\n",
    "                                      + \" \" + \\\n",
    "                                      threshold_signs[index] \\\n",
    "                                      + \" \" + str(int(threshold_values[index])))\n",
    "        else:\n",
    "            list_of_statements[unique_features.index(features_used[index])] \\\n",
    "            += \" and \" + threshold_signs[index] + \" \" + str(int(threshold_values[index]))\n",
    "\n",
    "    return list_of_statements, features_not_used\n",
    "\n",
    "# function 3 - creates a diagram of the decision tree with the decision path \n",
    "# for a given review highlighted and saves it as a png\n",
    "def create_tree_diagram_png(dt, feature_names, class_names, filename, sample):\n",
    "    \n",
    "    # get decision tree classifier in DOT (graphviz) format\n",
    "    dot_data = tree.export_graphviz(dt, out_file=None, \n",
    "                                feature_names=feature_names, \n",
    "                                    class_names=class_names, filled=True, \n",
    "                                    rounded=True, special_characters=True, node_ids = False)\n",
    "    \n",
    "    graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "    \n",
    "    # set all nodes to be of a white colour\n",
    "    for node in graph.get_node_list():\n",
    "        node.set_fillcolor('white')\n",
    "        \n",
    "    # set colour of leaf nodes depending on their class (fake or genuine)\n",
    "    for node in graph.get_node_list():\n",
    "        d = node.get_attributes()\n",
    "        if(\"label\" in d):\n",
    "            labels = node.get_attributes()['label'].split('<br/>')\n",
    "            for i, label in enumerate(labels):\n",
    "                if(label.startswith('class = ')):\n",
    "                    # colour nodes depending on their class\n",
    "                    if('Fake' in label):\n",
    "                        # set colour of nodes with fake as majority vote\n",
    "                        node.set_fillcolor('gray75')\n",
    "                    elif('Genuine' in label):\n",
    "                        # set colour of nodes with genuine as majority vote\n",
    "                        node.set_fillcolor('gray97')\n",
    "\n",
    "    # get decision path for chosen review sample\n",
    "    decision_path = dt.decision_path(sample)\n",
    "\n",
    "    # loop through each node in tree and its associated decision-path value, \n",
    "    # i.e., if the node is part of the decision path \n",
    "    # then it has a value of 1, otherwise, it has a value of 0\n",
    "    for node_counter, node_value in enumerate(decision_path.toarray()[0]):\n",
    "        \n",
    "        # if node is not part of decision path for sample, continue \n",
    "        if(node_value == 0):\n",
    "            continue\n",
    "        # set colour of node part of decision path for sample\n",
    "        dot_node = graph.get_node(str(node_counter))[0]\n",
    "        dot_node.set_fillcolor('darkseagreen1')\n",
    "        \n",
    "    # export updated graph to a png\n",
    "    graph.write_png(filename)\n",
    "\n",
    "# function 4 - prepares the string to wrap in the \n",
    "# HTML document to be displayed to the user\n",
    "def prepare_string_to_wrap(index, review_text, reviewer_id, \n",
    "                           decisions_made, features_not_used, predicted_string):\n",
    "    \n",
    "    string_to_wrap = \"\"\n",
    "\n",
    "    # add title\n",
    "    index_string = \"<h2>Classification Explanation For Selected Review</h2>\"\n",
    "    string_to_wrap += index_string\n",
    "    string_to_wrap += \"<br/>\"\n",
    "    \n",
    "    # add review text\n",
    "    string_to_wrap += \"<em>\" + review_text + \"</em>\"\n",
    "    string_to_wrap += \"<br/>\"\n",
    "    \n",
    "    # add reviewer ID\n",
    "    string_to_wrap += \"- posted by reviewer: \" + reviewer_id\n",
    "    string_to_wrap += \"<br/><br/>\"\n",
    "    \n",
    "    # add classification and accuracy to string\n",
    "    string_to_wrap += \"<mark>\" + predicted_string + \"</mark>\"\n",
    "    string_to_wrap += \"<br/>\"\n",
    "    \n",
    "    # add line to separate classification from decisions made\n",
    "    string_to_wrap += \"<hr>\"\n",
    "    \n",
    "    # add decisions made to string\n",
    "    string_to_wrap += \"<br/>\"\n",
    "    string_to_wrap += \"This estimation is based on the model's \" + \\\n",
    "    \"consideration of the following attributes of the review and the reviewer:<br/>\"\n",
    "    string_to_wrap += \"<ul>\"\n",
    "    for decision in decisions_made:\n",
    "        string_to_wrap += \"<li>\"\n",
    "        string_to_wrap += decision\n",
    "        string_to_wrap += \"</li>\"\n",
    "    string_to_wrap += \"</ul>\"\n",
    "    #string_to_wrap += \"<br/>\"\n",
    "    \n",
    "    # add info about features NOT considered in decisions\n",
    "    string_to_wrap += \"The following features were not \" + \\\n",
    "    \"considered in the decision-making process for this review:\"\n",
    "    string_to_wrap += \"<ul>\"\n",
    "    for feature in features_not_used:\n",
    "        string_to_wrap += \"<li>\"\n",
    "        string_to_wrap += feature\n",
    "        string_to_wrap += \"</li>\"\n",
    "    string_to_wrap += \"</ul>\"\n",
    "        \n",
    "    # add information about visualisation\n",
    "    string_to_wrap += \"This reasoning can also be \" + \\\n",
    "    \"seen visually in the visualisation below.\"\n",
    "    \n",
    "    return string_to_wrap\n",
    "\n",
    "# function 5 - wraps decision path text, decision path image \n",
    "# and other information in an HTML document and displays it in the users browser\n",
    "def wrap_output_in_HTML(title, text, image):\n",
    "    \n",
    "    current_datetime = datetime.datetime.today().strftime(\"%d/%m/%Y - %H:%M:%S\")\n",
    "\n",
    "    # create a new HTML file\n",
    "    filename = title + '.html'\n",
    "    f = open(filename,'w')\n",
    "    \n",
    "    # create basic HTML structure with indications\n",
    "    # of where strings will be embedded\n",
    "    wrapper = \"\"\"<html>\n",
    "    <head>\n",
    "    <style>\n",
    "    body {\n",
    "        background-color: WhiteSmoke;\n",
    "    }\n",
    "    </style>\n",
    "    <title>%s - %s</title>\n",
    "    </head>\n",
    "    <body>\n",
    "    \n",
    "    <p>%s</p>\n",
    "    <a href=%s target=\"_blank\">Click here to open visualisation</a>\n",
    "    </body>\n",
    "    </html>\"\"\"\n",
    "\n",
    "    # embed the document title, current datetime, decision path text\n",
    "    # and tree visualisation file location in the HTML document\n",
    "    whole = wrapper % (title, current_datetime, text, image)\n",
    "    f.write(whole)\n",
    "    f.close()\n",
    "    \n",
    "    path = \"file://\" + str(Path().absolute()) + \"/%s\"\n",
    "    path = path % (filename)\n",
    "    \n",
    "    return path\n",
    "\n",
    "####################################################\n",
    "####################################################\n",
    "\n",
    "\n",
    "# Main code with user input loop\n",
    "\n",
    "###\n",
    "# SET PATH FOR CLASSIFIER AND TEST DATA HERE\n",
    "path = \"/Users/artembutbaev/OneDrive/University of Bath 20-21 \" + \\\n",
    "\"(Year 4)/CM - Individual Project/2. Code/Model Building/\"\n",
    "###\n",
    "\n",
    "# load decision tree classifier from path above\n",
    "with open(path + 'dt_final.pkl', 'rb') as f:\n",
    "    dt_final = pickle.load(f)\n",
    "# load test data (features only) from path above\n",
    "with open(path + 'x_test.pkl', 'rb') as f:\n",
    "    x_test = pickle.load(f)\n",
    "# load associated review data from path above\n",
    "with open(path + 'df_test.pkl', 'rb') as f:\n",
    "    df_test = pickle.load(f)\n",
    "\n",
    "# set feature names to be displayed in front end\n",
    "feature_names_readable = ['Does the reviewer have a profile?', 'Posts by reviewer', \\\n",
    "                          '\\'Useful\\' votes', 'Maximum word importance score (TF-IDF)', \\\n",
    "                          'Length of review (characters)', '\\'Cool\\' votes', \\\n",
    "                          '\\'Funny\\' votes', 'Maximum posts by reviewer in a single day', \\\n",
    "                          'Count of numbers in review', 'Count of symbols in review']\n",
    "# set output class names to be displayed in front end \n",
    "class_names_readable = ['Genuine', 'Fake']\n",
    "\n",
    "# User input loop - user selects a review they would like classified and explained\n",
    "# an explanation and tree diagram is generated, embedded within an HTML document\n",
    "# and displayed in the user's web-browser in a new tab\n",
    "while(True):\n",
    "\n",
    "    print(\"Enter a review index from 0 to\", len(x_test) - 1, \":\")\n",
    "    user_input = input()\n",
    "    index_chosen = int(user_input)\n",
    "    review_text = df_test[\"reviewContent\"].iloc[index_chosen]\n",
    "    print(\"Is this the review you want to classify? (y/n)\\n\")\n",
    "    print(review_text)\n",
    "    user_input_2 = input()\n",
    "\n",
    "    if(user_input_2 == 'y'):\n",
    "        print(\"Generating output...\")\n",
    "        \n",
    "        # 1. get review sample from test data for chosen index\n",
    "        # and review text and reviewer ID from review data\n",
    "        sample = x_test.iloc[index_chosen:index_chosen+1]\n",
    "        review_text = df_test[\"reviewContent\"].iloc[index_chosen]\n",
    "        reviewer_id = df_test[\"reviewerID\"].iloc[index_chosen]\n",
    "\n",
    "        # 2. get decision path information (features used and the threshold values)\n",
    "        features_used, threshold_values, threshold_signs, predicted_string = \\\n",
    "        get_decision_path_info(dt_final, feature_names_readable, sample)\n",
    "        # write the decision path information \n",
    "        # as a series of decisions in text form, detailing\n",
    "        # the features used and not used in the model's decision making\n",
    "        decisions_made, not_used = \\\n",
    "        write_decisions(features_used, feature_names_readable, threshold_values, threshold_signs)\n",
    "\n",
    "        # 3. generate tree diagram with highlighted decision path (save as png)\n",
    "        create_tree_diagram_png(dt_final, x_test.columns, \\\n",
    "                                 class_names_readable, 'decision_path_1.png', sample)\n",
    "\n",
    "        # 4. prepare the written explanation to wrap in the HTML document\n",
    "        string_to_wrap = prepare_string_to_wrap(index_chosen, review_text, reviewer_id, \n",
    "                                                decisions_made, not_used, predicted_string)\n",
    "        image_to_wrap = \"decision_path_1.png\"\n",
    "        \n",
    "        # 5. embed the written explanation and tree diagram in HTML document\n",
    "        path = wrap_output_in_HTML(\"output1\", string_to_wrap, image_to_wrap)\n",
    "        # open the prepared HTML document in the user's web browser\n",
    "        webbrowser.open_new_tab(path)\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
